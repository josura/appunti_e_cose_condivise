graph mining: trovare sottografi in un database di grafi, vedere quali sono i frequenti che superano una certa soglia(si confronta il supporto, cioè la frequenza del sottografo nel database, con la soglia),costruzione di un modello che possa predire nodi o archi futuri, che possa classificare i grafi in base alle loro caratteristiche comuni, che possa estrapolare le caratteristiche(feature extraction) più importanti del grafo, e talvolta queste caratteristiche devono essere una chiave per il grafo e per algoritmi che le usano per ottimizzare(indexing o altro)

il problema assume somiglianza con quello dei frequent subset(con algoritmo a-priori)
sottografi frequenti con meno nodi devono essere per forza in sottografi frequenti con più nodi
in un database di grafi, abbiamo gli item che rappresentano nodi, i record(grafi) che rappresentano transazioni, e le relazioni tra gli item che vengono rappresentate come archi(vedere immagine sulle slide per visione)

Frequent Subgraph Mining: 
identificare tutti i sottografi frequenti in un database di grafi
si conta il numero di grafi che contengono il grafo query(calcolo del supporto)
se il supporto è maggiore di una soglia allora il sottografo è frequente
solitamente però più che il supporto si usa la frequenza relativa(rapporto tra supporto e numero di record), in questo caso otteniamo una percentuale(probabilità che prendento un record a caso del dataset, quel record conterrà quel sottografo)
da input di un dataset rappresentato a grafo, usiamo il nostro algoritmo.
creazione di sottografi, pruning, aggiunta all'insieme di grafi frequenti, all'inizio cerchiamo tutti i nodi ed archi frequenti nel database e li aggiungiamo all'insieme dei risultati, poi a partire dall'insieme dei sottografi già frequenti, (k-1 con k>=3) costruiamo i possibili candidati, eliminiamo sia i candidati ridondanti(ripetuti) che quelli che non soddisfano la regola A-priori, cioè i candidati che non sono frequenti e che contengono almeno un sottografo che non è frequente, e procediamo con il conteggio delle frequenze, stando attenti alla soglia(approccio bottom-up)
se si vuole usare apriori bisogna sviluppare un approccio breadth first(prima in ampiezza),prima sottografi con k nodi, poi k+1 nodi, partendo da grafi con pochi nodi(all' inizio 1 o 2 boh), e si arriva a osservare tutti i possibili candidati fino alla fine delle possibilità

si potrebbe usare anche un approccio DFS, controllando ed espandendo il supporto di un singolo sottografo candidato, richiede meno memoria ma è meno efficace nel pruning


generazioni join based con nodi o con archi(creazione di nuovi candidati da vecchi candidati tramite somma di nodi o di archi(vedere su internet e le slide per vedere come farlo))
join-based come dice la parola uniamo più sottografi frequenti con k nodi per crearne uno con k+1 nodi,questa unione è ovviamente possibile se i due sottografi hanno almeno k-1 nodi in comune, la generazione può essere fatta pure con gli archi

i core sono le parti in comune tra due grafi
la generazione di candidati può portare ad un insieme di candidati abbastanza grande(ci possono essere anche candidati che siano matchati)
con la generazione extend based , ci basiamo su un algoritmo dfs(creazione di un albero DFS), dal cammino più a destra del DFS-tree creato aggiungiamo o un nodo o un arco(usiamo dfs per evitare di avere duplicati, quindi non avremo ridondanze)
pruning sulle ridondanze: lo stesso sottografo lo posso ottenere più volte, come facciamo a vedere se i grafi siano isomorfismi(matchati), abbiamo bisogno di una rappresentazione univoca che ci permetta di confrontarli(come già visto nelle scorse lezioni), la rappresentazione del grafo la facciamo in base al suo tipo(sparso o denso come già visto ad algortmi)

due grafi potrebbero avere matrici o liste di adiacenza diverse ma essere comunque isomorfi, non sono adatte a risolvere le ridondanze

a partire dalla matrice di adiacenza posso definire una stringa chiamata stringa di adiacenza(ottenuta concatenando le righe o la parte triangolare superiore nel caso di archi indirezionato), le stringhe che possiamo ottenere sono le permutazioni dei nodi(con arco o no, quindi qualcosa di particolare non so calcolarla in questo momento, ma se non mi sbaglio è il fattoriale dato che sono le permutazioni,solo che ci sono elementi ripetuti quindi non saprei) , scegliamo la forma canonica(scegiamo la stringa che dia il numero più piccolo o più grande), se due grafi sono isomorfi allora avranno la stessa forma canonica.

un sottografo frequente potrebbe essere banale(collegato al concetto di significatività statistica), cioè potrebbe non essere rilevante. pattern banale(nodo o arco frequente o along those lines), calcolare la significatività statistica di un pattern può essere importante per la qualità del modello, è una azione che può essere fatta in post-processing, cioè dopo aver costruito il modello.
la significatività viene calcolata rispetto ad un database di background, opportunamente costruito, formato dal database iniziale e costruito da n grafi random a partire da ciascun grafo del database iniziale(si prendono come base e probabilmente vengono creati nuovi grafi a partire da quelli del database originario, modificando edge e nodi o cose del genere)
si ripete la creazione del database di background un certo numero di volte, fino ad avere molti database di background  
creiamo un database di grafi random(creiamo k database in modo iterativo), calcoliamo il supporto del sottografo di riferimento in ciascuno dei k database di background, al termine di questo passo si ottiene una distribuzione di probabilità dei valori di X
calcoliamo la prob di osservare un supporto X maggiore o uguale al supporto X0 osservato nel database iniziale da analizzare, questa probabilità è il p-value.
se il p-value è minore di una soglia, allora S è significativo come sottografo frequente.(in pratica l'ipotesi nulla è che il modello random abbia un supporto maggiore o uguale a quello del grafo normale, quindi il sottografo è banale dato che è stato creato da grafi random), vedere le slide per una rappresentaione visuale del p-value inteso.


algoritmo di edge swapping(per la creazione di un grafo random a partire da un grafo G), in pratica swappiamo gli edge come implicato dal nome, con questo algoritmo cerchiamo di mantenere il grado dei nodi, il procedimento viene iterato un numero alto di volte per vedere effettivamente un'alta randomicità?

ALGORITMO FSG:
la strategia è BFS(di fatto implementa l'apriori).
generiamo i candidati con join-based per aggiunta di singoli archi
usiamo la forma canonica per la creazione di core(matchando le stringhe, cerchiamo i sottografi isomorfi in modo veloce e univoco, senza ambiguazioni)
riguardare inverted list per ottimizzazioni(da quel che ho capito un sottografo di n nodi è presente solo se i suoi sottografi n-1 sono presenti),cioè è una cosa che dipende tutta dalle transazioni(Transaction identifier), cioè i grafi che contengono il sottografo frequente
con il pruning filtriamo i grafi che ci interessano, cioè solo i grafi per cui valgono quelle regole

ALGORITMO GSPAN:
gspan non di basa sull'apriori, si basa sul dfs, i sottografi vengono rappresentati tramite dfs code(la parte del calcolo non l'ho capita molto bene, mi sembrava simile all'ordinamento topologico ma non saprei dopo aver letto le varie definizioni)



altro problema è la frequenza di sottografi nello stesso grafo(mining a singolo grafo). con la regola apriori bisogna stare attento  perchè possiamo avere grafi più grandi formati da sotto grafi che hanno una frequenza maggiore rispetto ai sottografi di cui sono formati(teoricamente non è ammesso dall'apriori).
Comunque ci si può ricondurre alle strategie usate per il graph mining normale(con le opportune modifiche), facendo attenzione al fatto che siamo comunque nello stasso grafo.
varie strategie di ricerca dei sottografi(nelle slide perchè mi secca scrivere e voglio sentire, e continua a farlo dalle slide perchè sinceramente mi scazza e lo trovo inutile sorry)
